# API ëª…ì„¸ì„œ

## ğŸ“‹ ëª©ì°¨

- [ì¸ì¦](#ì¸ì¦)
- [Chat Completions API](#chat-completions-api)
  - [ê¸°ë³¸ ìš”ì²­](#ê¸°ë³¸-ìš”ì²­)
  - [ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­](#ìŠ¤íŠ¸ë¦¬ë°-ìš”ì²­)
  - [Function Calling](#function-calling)
- [ì—ëŸ¬ ì²˜ë¦¬](#ì—ëŸ¬-ì²˜ë¦¬)

---

## ğŸ” ì¸ì¦

í˜„ì¬ ë²„ì „ì€ API í‚¤ ì¸ì¦ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ìš”ì²­ì€ ì„œë²„ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ëœ Gemini API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ğŸ’¬ Chat Completions API

### ì—”ë“œí¬ì¸íŠ¸

```
POST /chat/completions
POST /v1/chat/completions
```

OpenAI Chat Completions APIì™€ ì™„ë²½íˆ í˜¸í™˜ë˜ëŠ” ì±„íŒ… ì™„ì„± ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.

---

### ê¸°ë³¸ ìš”ì²­

#### Request

**Headers:**
```
Content-Type: application/json
```

**Body Parameters:**

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|------|------|--------|------|
| `model` | string | âœ… | - | ì‚¬ìš©í•  ëª¨ë¸ëª… |
| `messages` | array | âœ… | - | ëŒ€í™” ë©”ì‹œì§€ ë°°ì—´ |
| `temperature` | float | âŒ | 0.7 | ì‘ë‹µì˜ ë¬´ì‘ìœ„ì„± (0.0 ~ 2.0) |
| `max_tokens` | integer | âŒ | 1000 | ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ |
| `stream` | boolean | âŒ | false | ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™” |
| `top_p` | float | âŒ | 1.0 | í•µì‹¬ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° |
| `n` | integer | âŒ | 1 | ìƒì„±í•  ì‘ë‹µ ê°œìˆ˜ |
| `stop` | string/array | âŒ | null | ìƒì„± ì¤‘ë‹¨ ì‹œí€€ìŠ¤ |
| `presence_penalty` | float | âŒ | 0 | ìƒˆë¡œìš´ ì£¼ì œ íŒ¨ë„í‹° (-2.0 ~ 2.0) |
| `frequency_penalty` | float | âŒ | 0 | ë°˜ë³µ íŒ¨ë„í‹° (-2.0 ~ 2.0) |

**Messages í˜•ì‹:**

```json
{
  "role": "user|assistant|system",
  "content": "ë©”ì‹œì§€ ë‚´ìš©"
}
```

#### Request Example

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Hello! How are you?"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 1000
}
```

#### Response

**Status Code:** `200 OK`

**Body:**

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677858242,
  "model": "gpt-4",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! I'm doing well, thank you for asking. How can I assist you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 18,
    "total_tokens": 37
  }
}
```

**Response Fields:**

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `id` | string | ê³ ìœ í•œ ìš”ì²­ ID |
| `object` | string | ê°ì²´ íƒ€ì… (í•­ìƒ "chat.completion") |
| `created` | integer | Unix íƒ€ì„ìŠ¤íƒ¬í”„ |
| `model` | string | ì‚¬ìš©ëœ ëª¨ë¸ëª… |
| `choices` | array | ìƒì„±ëœ ì‘ë‹µ ë°°ì—´ |
| `choices[].index` | integer | ì„ íƒì§€ ì¸ë±ìŠ¤ |
| `choices[].message` | object | ì‘ë‹µ ë©”ì‹œì§€ |
| `choices[].message.role` | string | ì—­í•  (í•­ìƒ "assistant") |
| `choices[].message.content` | string | ì‘ë‹µ ë‚´ìš© |
| `choices[].finish_reason` | string | ì¢…ë£Œ ì´ìœ  ("stop", "length", "tool_calls") |
| `usage` | object | í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ |
| `usage.prompt_tokens` | integer | ì…ë ¥ í† í° ìˆ˜ |
| `usage.completion_tokens` | integer | ì¶œë ¥ í† í° ìˆ˜ |
| `usage.total_tokens` | integer | ì´ í† í° ìˆ˜ |

---

### ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­

Server-Sent Events (SSE)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

#### Request

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "user",
      "content": "Write a short story about a robot."
    }
  ],
  "stream": true
}
```

#### Response

**Status Code:** `200 OK`

**Content-Type:** `text/event-stream`

**ìŠ¤íŠ¸ë¦¼ í˜•ì‹:**

```
data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"Once"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"content":" upon"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"content":" a"},"finish_reason":null}]}

...

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

**Chunk êµ¬ì¡°:**

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `id` | string | ê³ ìœ í•œ ìš”ì²­ ID |
| `object` | string | ê°ì²´ íƒ€ì… (í•­ìƒ "chat.completion.chunk") |
| `created` | integer | Unix íƒ€ì„ìŠ¤íƒ¬í”„ |
| `model` | string | ì‚¬ìš©ëœ ëª¨ë¸ëª… |
| `choices[].index` | integer | ì„ íƒì§€ ì¸ë±ìŠ¤ |
| `choices[].delta` | object | ì¦ë¶„ ë©”ì‹œì§€ |
| `choices[].delta.role` | string | ì—­í•  (ì²« ì²­í¬ì—ë§Œ í¬í•¨) |
| `choices[].delta.content` | string | ì¦ë¶„ ì½˜í…ì¸  |
| `choices[].finish_reason` | string/null | ì¢…ë£Œ ì´ìœ  (ë§ˆì§€ë§‰ ì²­í¬ì—ë§Œ í¬í•¨) |

**ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ:**
- ë§ˆì§€ë§‰ ì²­í¬ëŠ” `finish_reason`ì´ í¬í•¨ë¨
- ìµœì¢… ë©”ì‹œì§€ë¡œ `data: [DONE]` ì „ì†¡

---

### Function Calling (Tool Calls)

ëª¨ë¸ì´ ì™¸ë¶€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Request

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "user",
      "content": "What's the weather like in Seoul?"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and country, e.g. Seoul, South Korea"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"],
              "description": "The temperature unit to use"
            }
          },
          "required": ["location"]
        }
      }
    }
  ],
  "tool_choice": "auto"
}
```

**Tool Parameters:**

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|---------|------|------|------|
| `tools` | array | âŒ | ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ |
| `tools[].type` | string | âœ… | ë„êµ¬ íƒ€ì… (í•­ìƒ "function") |
| `tools[].function` | object | âœ… | í•¨ìˆ˜ ì •ì˜ |
| `tools[].function.name` | string | âœ… | í•¨ìˆ˜ëª… |
| `tools[].function.description` | string | âœ… | í•¨ìˆ˜ ì„¤ëª… |
| `tools[].function.parameters` | object | âœ… | JSON Schema í˜•ì‹ì˜ íŒŒë¼ë¯¸í„° ì •ì˜ |
| `tool_choice` | string/object | âŒ | ë„êµ¬ ì„ íƒ ë°©ì‹ ("auto", "none", ë˜ëŠ” íŠ¹ì • í•¨ìˆ˜ ì§€ì •) |

#### Response (Tool Call)

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677858242,
  "model": "gpt-4",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\": \"Seoul, South Korea\", \"unit\": \"celsius\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": {
    "prompt_tokens": 82,
    "completion_tokens": 17,
    "total_tokens": 99
  }
}
```

**Tool Call Fields:**

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `tool_calls` | array | í˜¸ì¶œí•  ë„êµ¬ ëª©ë¡ |
| `tool_calls[].id` | string | ë„êµ¬ í˜¸ì¶œ ID |
| `tool_calls[].type` | string | ë„êµ¬ íƒ€ì… (í•­ìƒ "function") |
| `tool_calls[].function.name` | string | í˜¸ì¶œí•  í•¨ìˆ˜ëª… |
| `tool_calls[].function.arguments` | string | JSON ë¬¸ìì—´ í˜•ì‹ì˜ í•¨ìˆ˜ ì¸ì |

#### Request (Tool Call Result)

ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ëª¨ë¸ì— ì „ë‹¬:

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "user",
      "content": "What's the weather like in Seoul?"
    },
    {
      "role": "assistant",
      "content": null,
      "tool_calls": [
        {
          "id": "call_abc123",
          "type": "function",
          "function": {
            "name": "get_weather",
            "arguments": "{\"location\": \"Seoul, South Korea\", \"unit\": \"celsius\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "tool_call_id": "call_abc123",
      "content": "{\"temperature\": 22, \"condition\": \"sunny\"}"
    }
  ]
}
```

#### Response (Final Answer)

```json
{
  "id": "chatcmpl-abc456",
  "object": "chat.completion",
  "created": 1677858252,
  "model": "gpt-4",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The weather in Seoul is currently sunny with a temperature of 22Â°C."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 120,
    "completion_tokens": 18,
    "total_tokens": 138
  }
}
```

---

### Function Calling with Streaming

ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì—ì„œë„ Function Callingì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Request

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "user",
      "content": "What's the weather in Tokyo and Seoul?"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and country"
            }
          },
          "required": ["location"]
        }
      }
    }
  ],
  "stream": true
}
```

#### Response Stream

```
data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"role":"assistant","tool_calls":[{"index":0,"id":"call_abc123","type":"function","function":{"name":"get_weather","arguments":""}}]},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"{\""}}]},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"location"}}]},"finish_reason":null}]}

...

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677858242,"model":"gpt-4","choices":[{"index":0,"delta":{},"finish_reason":"tool_calls"}]}

data: [DONE]
```

**ìŠ¤íŠ¸ë¦¬ë° Tool Call íŠ¹ì§•:**
- `tool_calls` ë°°ì—´ì˜ ê° ìš”ì†ŒëŠ” `index`ë¡œ ì‹ë³„
- `function.arguments`ëŠ” ì²­í¬ ë‹¨ìœ„ë¡œ ì ì§„ì ìœ¼ë¡œ ì „ë‹¬
- ì²« ì²­í¬ì—ì„œ í•¨ìˆ˜ëª…(`name`)ê³¼ ID ì œê³µ
- ì´í›„ ì²­í¬ì—ì„œëŠ” `arguments` ë¬¸ìì—´ì˜ ì¼ë¶€ë¶„ë§Œ ì „ë‹¬
- ë§ˆì§€ë§‰ ì²­í¬ì—ì„œ `finish_reason: "tool_calls"` ì„¤ì •

---

## âš ï¸ ì—ëŸ¬ ì²˜ë¦¬

### ì—ëŸ¬ ì‘ë‹µ í˜•ì‹

ëª¨ë“  ì—ëŸ¬ëŠ” OpenAI í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.

```json
{
  "error": {
    "message": "ì—ëŸ¬ ë©”ì‹œì§€",
    "type": "error_type",
    "code": 400
  }
}
```

### ì£¼ìš” ì—ëŸ¬ ì½”ë“œ

| HTTP ìƒíƒœ ì½”ë“œ | ì—ëŸ¬ íƒ€ì… | ì„¤ëª… |
|---------------|----------|------|
| 400 | `invalid_request_error` | ì˜ëª»ëœ ìš”ì²­ í˜•ì‹ ë˜ëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½ |
| 401 | `authentication_error` | ì¸ì¦ ì‹¤íŒ¨ |
| 429 | `rate_limit_error` | API í˜¸ì¶œ í•œë„ ì´ˆê³¼ |
| 500 | `api_error` | ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ |
| 503 | `service_unavailable` | ì„œë¹„ìŠ¤ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš© ë¶ˆê°€ |

### ì—ëŸ¬ ì˜ˆì œ

#### 400 Bad Request - í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½

**Request:**
```json
{
  "model": "gpt-4"
}
```

**Response:**
```json
{
  "error": {
    "message": "Invalid request",
    "type": "invalid_request_error",
    "code": 400
  }
}
```

#### 429 Rate Limit Error

**Response:**
```json
{
  "error": {
    "message": "Rate limit exceeded. Please retry after some time.",
    "type": "rate_limit_error",
    "code": 429
  }
}
```

#### 500 Internal Server Error

**Response:**
```json
{
  "error": {
    "message": "An unexpected error occurred while processing your request.",
    "type": "api_error",
    "code": 500
  }
}
```

---

## ğŸ“ ì‚¬ìš© ì˜ˆì œ

### Python (OpenAI SDK)

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="dummy"  # API í‚¤ëŠ” ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ SDKì—ì„œ í•„ìˆ˜
)

# ê¸°ë³¸ ìš”ì²­
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
print(response.choices[0].message.content)

# ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
stream = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Write a poem."}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### cURL

```bash
# ê¸°ë³¸ ìš”ì²­
curl -X POST http://localhost:8000/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'

# ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
curl -X POST http://localhost:8000/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "Write a story."}
    ],
    "stream": true
  }' \
  --no-buffer
```

### JavaScript (Node.js)

```javascript
const OpenAI = require('openai');

const client = new OpenAI({
  baseURL: 'http://localhost:8000/v1',
  apiKey: 'dummy'
});

async function main() {
  // ê¸°ë³¸ ìš”ì²­
  const response = await client.chat.completions.create({
    model: 'gpt-4',
    messages: [
      { role: 'user', content: 'Hello!' }
    ]
  });
  console.log(response.choices[0].message.content);

  // ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
  const stream = await client.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: 'Write a poem.' }],
    stream: true
  });

  for await (const chunk of stream) {
    process.stdout.write(chunk.choices[0]?.delta?.content || '');
  }
}

main();
```

---

## ğŸ”§ ì¶”ê°€ ì •ë³´

### ì§€ì›ë˜ëŠ” ë©”ì‹œì§€ ì—­í•  (Roles)

| ì—­í•  | ì„¤ëª… |
|-----|------|
| `system` | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ëª¨ë¸ì˜ í–‰ë™ ì •ì˜) |
| `user` | ì‚¬ìš©ì ë©”ì‹œì§€ |
| `assistant` | ì–´ì‹œìŠ¤í„´íŠ¸(ëª¨ë¸) ì‘ë‹µ |
| `tool` | ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ (Function Calling ì‹œ) |

### Finish Reasons

| ê°’ | ì„¤ëª… |
|----|------|
| `stop` | ëª¨ë¸ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µ ì™„ë£Œ |
| `length` | max_tokens ì œí•œì— ë„ë‹¬ |
| `tool_calls` | ëª¨ë¸ì´ í•¨ìˆ˜ í˜¸ì¶œì„ ìš”ì²­ |
| `content_filter` | ì½˜í…ì¸  í•„í„°ì— ì˜í•´ ì¤‘ë‹¨ |

### ëª¨ë¸ ë§¤í•‘

ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëª¨ë¸ëª…ì€ `opencode.json` ì„¤ì • íŒŒì¼ì— ì •ì˜ëœ ë§¤í•‘ì— ë”°ë¼ ì‹¤ì œ Gemini ëª¨ë¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

ì˜ˆ:
- `gpt-4` â†’ `gemini-1.5-pro`
- `gpt-3.5-turbo` â†’ `gemini-1.5-flash`

---

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

API ì‚¬ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
